{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5558cc69",
   "metadata": {},
   "source": [
    "# Peak fitting for Scherrer analysis\n",
    "\n",
    "## Data prep before this step\n",
    "\n",
    "- perform batch integration on a set of GIWAXS data\n",
    "- the integrations should all be in the same angular range\n",
    "- these integrations should be put in a CSV file, where the first column is the q-values and the following columns are the integrations\n",
    "\n",
    "\n",
    "## Fitting function\n",
    "\n",
    "- this script fits an isolated peak to $ y = mx + c + Gaussian$\n",
    "- represented by $y = mx + c + A \\cdot e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}$\n",
    "- $x$ and $y$ are q-values and integrated intensities, repsectively (`x`, `y` in the script)\n",
    "- $m$ and $c$ are linear background (`m`, `c`)\n",
    "- $A$ is amplitude of Gaussian peak (`A`)\n",
    "- $\\mu$ is mean of Gaussian  (`mu`) \n",
    "- $\\sigma$ is standard deviation / width of Gaussian  (`sigma`) \n",
    "- alternatively, can use Lorentzian fit defined as $L(x) = \\frac{A}{\\pi \\sigma [1+(\\frac{\\pi - \\mu}{\\sigma})^2]}$\n",
    "- in Lorenztian $A$, $\\mu$ and $\\sigma$ are analogous / similar physical interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0359135",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries and modules here ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "from scipy.optimize import OptimizeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### all functions used in script ###\n",
    "\n",
    "# combined linear + Gaussian function\n",
    "def linear_gaussian_func(x, m, c, A, mu, sigma):\n",
    "    linear_part = m * x + c\n",
    "    gaussian_part = A * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "    return linear_part + gaussian_part\n",
    "\n",
    "# combined linear + Lorentzian function\n",
    "def linear_lorentzian_func(x, m, c, A, mu, sigma):\n",
    "    linear_part = m * x + c\n",
    "    lorentzian_part = A / (np.pi * sigma * (1 + ((x - mu) / sigma) ** 2))\n",
    "    return linear_part + lorentzian_part\n",
    "\n",
    "\n",
    "# def linear_func(x, m, c):\n",
    "#     return m * x + c\n",
    "\n",
    "# def gaussian_func(x, A, mu, sigma):\n",
    "#     return A * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f66692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter filepath and filename \n",
    "# remember .csv at the end of filename\n",
    "#data = pd.read_csv('/home/goughl/Documents/beamtime_data/2409_DLS/SANS_samples/series_int/1D_int_20_60_iso_140_p2mImage1310975.csv')\n",
    "## out of plane data ##\n",
    "#data = pd.read_csv('/home/goughl/Documents/beamtime_data/2112_ESRF/MAR/ANDREAS/oct_paper/241029_AEL_IP_180_195.csv')\n",
    "\n",
    "## in-plane data ##\n",
    "data = pd.read_csv('/home/goughl/Documents/beamtime_data/2112_ESRF/MAR/ANDREAS/oct_paper/241029_AEL_OoP_250_265.csv')\n",
    "\n",
    "\n",
    "## minerva ex situ data\n",
    "#data = pd.read_csv('/home/goughl/Documents/beamtime_data/2409_DLS/for_database/1D_int_DCV4T_HT_0_45_integration_DCV4T_p2mImage_532361_1305575_unnormalised.csv')\n",
    "#data = pd.read_csv('/home/goughl/Documents/beamtime_data/2409_DLS/for_database/1D_int_DCV4T_HT_45_80_integration_DCV4T_p2mImage_532361_1305575_unnormalised.csv')\n",
    "#data = pd.read_csv('/home/goughl/Documents/beamtime_data/2409_DLS/for_database/1D_int_PTCDI_HT_50_80_integrated.csv')\n",
    "#data = pd.read_csv(\"/home/goughl/Documents/beamtime_data/EA_paper_processing/inplane_toplot.csv\")\n",
    "#data = pd.read_csv(\"/home/goughl/Documents/beamtime_data/2409_DLS/for_database/1D_EA_RT_15_40_IP_DCV5T_100nm_onEA.csv\")\n",
    "\n",
    "\n",
    "x = data.iloc[2:, 0].values.astype(float)  \n",
    "y_values = data.iloc[2:, 1:].values.astype(float) \n",
    "dataset_labels = data.columns[1:].tolist() \n",
    "\n",
    "print(dataset_labels)\n",
    "# # data should be in following format: first col is x values (the qvalues)\n",
    "# # following columns contain integrations with one peak isolated\n",
    "# script can be used with no prior BG removal\n",
    "# # in csv format!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e8553",
   "metadata": {},
   "source": [
    "## Important!! \n",
    "\n",
    "- only run linear-Gaussian fit OR linear-Lorentzian fit NOT both\n",
    "- the FWMH and therefore Scherrer calculations will be done on whichever of these cells was run last\n",
    "- best practice is to comment the one you're not using out so you don't get mixed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ec608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### LINEAR GAUSSIAN FIT ###\n",
    "\n",
    "# # define the min and max x values / q-range for fitting\n",
    "# # ## for OoP data, use range 0.4 to 1\n",
    "# # # fit_range_min = 0.4\n",
    "# # # fit_range_max = 1\n",
    "\n",
    "# # ## for IP data, use range 1.6 to 1.87\n",
    "# # fit_range_min = 1.6\n",
    "# # fit_range_max = 1.87\n",
    "\n",
    "# # empty list to store parameters for each dataset\n",
    "# params_list = []\n",
    "\n",
    "# for i in range(y_values.shape[1]):\n",
    "#     y = y_values[:, i]\n",
    "\n",
    "#     # masks data outside defined range\n",
    "#     fit_mask = (x >= fit_range_min) & (x <= fit_range_max)\n",
    "#     x_fit = x[fit_mask]\n",
    "#     y_fit = y[fit_mask]\n",
    "\n",
    "#     # initial guesses for m, c, A, mu, sigma\n",
    "#     initial_guess = [1, np.mean(y_fit), max(y_fit), x_fit[np.argmax(y_fit)], 0.1]\n",
    "\n",
    "#     # Fit the combined model with bounds to enforce positive sigma\n",
    "#     params, _ = curve_fit(\n",
    "#         linear_gaussian_func, \n",
    "#         x_fit, \n",
    "#         y_fit, \n",
    "#         p0=initial_guess, \n",
    "#         bounds=([-np.inf, -np.inf, -np.inf, -np.inf, 0], np.inf)  # Enforces positive sigma\n",
    "#     )\n",
    "    \n",
    "#     m, c, A, mu, sigma = params\n",
    "\n",
    "#     # Append the parameters for this dataset to the list\n",
    "#     params_list.append([dataset_labels[i], m, c, A, mu, sigma])\n",
    "\n",
    "#     # plotting\n",
    "#     fitted_model = linear_gaussian_func(x, m, c, A, mu, sigma)\n",
    "#     residuals = y - fitted_model\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.plot(x, y, 'b-', label=f'Original data (curve {dataset_labels[i]} Â°C)')\n",
    "#     plt.plot(x, fitted_model, 'r-', label=f'Fitted model')\n",
    "#     plt.axvline(fit_range_min, color='k', linestyle='--')\n",
    "#     plt.axvline(fit_range_max, color='k', linestyle='--')\n",
    "#     plt.legend()\n",
    "    \n",
    "# # residuals should just be slightly noisy - do this as sanity check     \n",
    "# #     plt.subplot(2, 1, 2)\n",
    "# #     plt.plot(x, residuals, 'g-', label='Residuals')\n",
    "# #     plt.legend()\n",
    "     \n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### LINEAR LORENTZIAN FIT ###\n",
    "\n",
    "# ## for OoP data, use range 0.4 to 1\n",
    "# # fit_range_min = 0.4\n",
    "# # fit_range_max = 1\n",
    "\n",
    "# ## for IP data, use range 1.6 to 1.87\n",
    "# fit_range_min = 0.4\n",
    "# fit_range_max = 1\n",
    "\n",
    "# params_list = []\n",
    "\n",
    "# for i in range(y_values.shape[1]):\n",
    "#     y = y_values[:, i]\n",
    "\n",
    "#     fit_mask = (x >= fit_range_min) & (x <= fit_range_max)\n",
    "#     x_fit = x[fit_mask]\n",
    "#     y_fit = y[fit_mask]\n",
    "\n",
    "#     # initial guesses for m, c, A, mu, sigma\n",
    "#     initial_guess = [\n",
    "#         1,                   # slope m\n",
    "#         np.mean(y_fit),      # intercept c\n",
    "#         max(y_fit),          # amplitude A\n",
    "#         x_fit[np.argmax(y_fit)],  # center mu\n",
    "#         0.1                  # width sigma (positive)\n",
    "#     ]\n",
    "\n",
    "#     try:\n",
    "#         params, _ = curve_fit(\n",
    "#             linear_lorentzian_func, \n",
    "#             x_fit, \n",
    "#             y_fit, \n",
    "#             p0=initial_guess, \n",
    "#             bounds=([-np.inf, -np.inf, -np.inf, fit_range_min, 0], [np.inf, np.inf, np.inf, fit_range_max, np.inf])\n",
    "#         )\n",
    "        \n",
    "#         m, c, A, mu, sigma = params\n",
    "#         params_list.append([dataset_labels[i], m, c, A, mu, sigma])\n",
    "\n",
    "#         fitted_model = linear_lorentzian_func(x, m, c, A, mu, sigma)\n",
    "#         residuals = y - fitted_model\n",
    "        \n",
    "#         plt.figure(figsize=(10, 6))\n",
    "        \n",
    "#         plt.subplot(2, 1, 1)\n",
    "#         plt.plot(x, y, 'b-', label=f'Original data (curve {dataset_labels[i]} Â°C)')\n",
    "#         plt.plot(x, fitted_model, 'r-', label=f'Fitted model')\n",
    "#         plt.axvline(fit_range_min, color='k', linestyle='--')\n",
    "#         plt.axvline(fit_range_max, color='k', linestyle='--')\n",
    "#         plt.title('Linear-Lorentzian fit')\n",
    "#         plt.legend()\n",
    "        \n",
    "# #         plt.subplot(2, 1, 2)\n",
    "# #         plt.plot(x, residuals, 'g-', label='Residuals')\n",
    "# #         plt.legend()\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"Fit did not converge for dataset {dataset_labels[i]}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params_df = pd.DataFrame(params_list, columns=['Dataset', 'm', 'c', 'A', 'mu', 'sigma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e9b5e",
   "metadata": {},
   "source": [
    "## Linear-Lorentzian fit with errors\n",
    "\n",
    "- the `curve_fit` function returns the fitted parameters and also the covariance matrix\n",
    "- the square root of the diagonal elements of the covariance matrix gives the standard errors of the fitted parameters\n",
    "- for sigma, the error is $\\Delta \\sigma = \\sqrt{Cov (\\sigma,\\sigma)}$\n",
    "- for the FWHM, the error is $\\Delta FWHM = 2.355 \\cdot \\Delta \\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b889f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LINEAR LORENTZIAN FIT  WITH ERRORS ###\n",
    "\n",
    "fit_range_min = 0.6\n",
    "fit_range_max = 1\n",
    "\n",
    "params_list_with_fwhm_and_errors = []  \n",
    "\n",
    "for i in range(y_values.shape[1]):\n",
    "    y = y_values[:, i]\n",
    "\n",
    "    fit_mask = (x >= fit_range_min) & (x <= fit_range_max)\n",
    "    x_fit = x[fit_mask]\n",
    "    y_fit = y[fit_mask]\n",
    "\n",
    "    initial_guess = [\n",
    "        1,                   # slope m\n",
    "        np.mean(y_fit),      # intercept c\n",
    "        max(y_fit),          # amplitude A\n",
    "        x_fit[np.argmax(y_fit)],  # center mu\n",
    "        0.1                  # width sigma (positive)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", OptimizeWarning)\n",
    "            params, covariance = curve_fit(\n",
    "                linear_lorentzian_func, \n",
    "                x_fit, \n",
    "                y_fit, \n",
    "                p0=initial_guess, \n",
    "                bounds=([-np.inf, -np.inf, -np.inf, fit_range_min, 0], [np.inf, np.inf, np.inf, fit_range_max, np.inf])\n",
    "            )\n",
    "        \n",
    "\n",
    "        m, c, A, mu, sigma = params\n",
    "        errors = np.sqrt(np.diag(covariance)) \n",
    "        sigma_error = errors[4] \n",
    "\n",
    "\n",
    "        fwhm = 2.355 * sigma\n",
    "        fwhm_error = 2.355 * sigma_error\n",
    "\n",
    "        params_list_with_fwhm_and_errors.append([dataset_labels[i], m, c, A, mu, sigma, fwhm, sigma_error, fwhm_error])\n",
    "\n",
    "\n",
    "        fitted_model = linear_lorentzian_func(x, m, c, A, mu, sigma)\n",
    "        residuals = y - fitted_model\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(x, y, 'b-', label=f'Original data (curve {dataset_labels[i]})')\n",
    "        plt.plot(x, fitted_model, 'r-', label=f'Fitted model')\n",
    "        plt.axvline(fit_range_min, color='k', linestyle='--')\n",
    "        plt.axvline(fit_range_max, color='k', linestyle='--')\n",
    "        plt.title('Linear-Lorentzian fit')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(x, residuals, 'g-', label='Residuals')\n",
    "        plt.axhline(0, color='k', linestyle='--', linewidth=0.8)\n",
    "        plt.xlabel('X-axis')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    except (RuntimeError, ValueError) as e:\n",
    "        print(f\"Fit did not converge for dataset {dataset_labels[i]}: {e}\")\n",
    "\n",
    "params_df = pd.DataFrame(\n",
    "    params_list_with_fwhm_and_errors, \n",
    "    columns=['Dataset', 'm', 'c', 'A', 'mu', 'sigma', 'FWHM', 'sigma_error', 'FWHM_error']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78df40",
   "metadata": {},
   "source": [
    "## FWMH calculation\n",
    "\n",
    "\n",
    "- Cell below calculates full width at half maximum (`fwhm`) using: $FWHM = 2\\sqrt{2 ln(2)} \\cdot \\sigma \\approx 2.355 \\sigma $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loops through calculated params and finds FWHM based on above formula using standard deviation sigma ###\n",
    "params_list_with_fwhm = []\n",
    "\n",
    "for params in params_list:\n",
    "    dataset_label, m, c, A, mu, sigma = params\n",
    "    fwhm = 2.355 * sigma  # FWHM calculation\n",
    "    params_list_with_fwhm.append([dataset_label, m, c, A, mu, sigma, fwhm])\n",
    "\n",
    "\n",
    "params_df = pd.DataFrame(params_list_with_fwhm, columns=['Dataset', 'm', 'c', 'A', 'mu', 'sigma', 'FWHM'])\n",
    "print(params_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf2337",
   "metadata": {},
   "source": [
    "## Scherrer equation calculation\n",
    "\n",
    "- cell below calculates crystallite coherence length $D_{hkl}$ (`D`) using the Scherrer equation\n",
    "- Scherrer equation is: $D_{hkl} = \\frac{2\\pi K}{ \\Delta q_{hkl}}$\n",
    "- $K$ is the Scherrer constant, assume to be 1 (`K`)\n",
    "- $\\Delta q_{hkl}$ is the FWHM of the diffraction peaks (`fwhm`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e16969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating coherence length of crystallites in nm ###\n",
    "\n",
    "K = 1  # Scherrer constant, assume to be 1\n",
    "\n",
    "params_df['D'] = (2 * np.pi * K) / params_df['FWHM'] / 10\n",
    "# division by 10 here is to convert from Angstrom to nanometers\n",
    "\n",
    "print(params_df[['Dataset', 'D']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185cdcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### plotting coherence length as a function of some variable ###\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# x_values = np.arange(len(params_df))\n",
    "# plt.plot(x_values, params_df['D'], marker='x', linestyle='-', color='r', label='D (nm)')\n",
    "\n",
    "\n",
    "# plt.xticks(x_values, params_df['Dataset'].values, rotation=45) \n",
    "\n",
    "\n",
    "# plt.xlabel('Temperature (Â°C)')\n",
    "# plt.ylabel('D (nm)')\n",
    "# plt.title('Coherence length as a function of temp')\n",
    "# plt.axhline(1.75, color='gray', lw=0.5, linestyle='--')  # first argument makes baseline y = arg (i.e. horiz line)\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c64e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIAL CASE WHERE TWO PEAKS OVERLAP ###\n",
    "\n",
    "\n",
    "def linear_double_lorentzian_func(x, m, c, A1, mu1, gamma1, A2, mu2, gamma2):\n",
    "    linear_part = m * x + c\n",
    "    lorentzian1 = A1 * gamma1**2 / ((x - mu1)**2 + gamma1**2)\n",
    "    lorentzian2 = A2 * gamma2**2 / ((x - mu2)**2 + gamma2**2)\n",
    "    return linear_part + lorentzian1 + lorentzian2\n",
    "\n",
    "def fit_double_lorentzian(data, x, label):\n",
    "\n",
    "    if label not in params_df['Dataset'].values:\n",
    "        print(f\"Dataset label '{label}' not found.\")\n",
    "        return\n",
    "\n",
    "    label_index = params_df[params_df['Dataset'] == label].index[0]\n",
    "    y = y_values[:, label_index]\n",
    "\n",
    "\n",
    "    fit_mask = (x >= fit_range_min) & (x <= fit_range_max)\n",
    "    x_fit = x[fit_mask]\n",
    "    y_fit = y[fit_mask]\n",
    "\n",
    "    # initial guesses, enter numbers based on visual inspection\n",
    "    initial_guess = [\n",
    "        1,                # slope (m) of the linear background\n",
    "        np.mean(y_fit),   # intercept (c) of the linear background\n",
    "        max(y_fit) / 2,   # amplitude of first Lorentzian (A1)\n",
    "        1.25,             # center of first Lorentzian (mu1)\n",
    "        0.07,             # width of first Lorentzian (gamma1)\n",
    "        max(y_fit) / 2,   # amplitude of second Lorentzian (A2)\n",
    "        1.45,             # center of second Lorentzian (mu2)\n",
    "        0.02              # width of second Lorentzian (gamma2)\n",
    "    ]\n",
    "\n",
    "    params, _ = curve_fit(linear_double_lorentzian_func, x_fit, y_fit, p0=initial_guess)\n",
    "    m, c, A1, mu1, gamma1, A2, mu2, gamma2 = params\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, 'b-', label=f'Original data ({label})Â°C')\n",
    "\n",
    "    combined_fit = linear_double_lorentzian_func(x, m, c, A1, mu1, gamma1, A2, mu2, gamma2)\n",
    "    plt.plot(x, combined_fit, 'r-', label='Double Lorentzian fit')\n",
    "\n",
    "    linear_part = m * x + c\n",
    "    plt.plot(x, linear_part, 'k--', label='Linear component')\n",
    "\n",
    "    lorentzian1 = A1 * gamma1**2 / ((x - mu1)**2 + gamma1**2)\n",
    "    lorentzian2 = A2 * gamma2**2 / ((x - mu2)**2 + gamma2**2)\n",
    "    plt.plot(x, lorentzian1 + linear_part, 'g--', label='Lorentzian 1')\n",
    "    plt.plot(x, lorentzian2 + linear_part, 'm--', label='Lorentzian 2')\n",
    "\n",
    "    plt.xlabel('q-values')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'Double Lorentzian Fit for {label}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    fwhm1 = 2 * abs(gamma1)\n",
    "    fwhm2 = 2 * abs(gamma2)\n",
    "    print(f\"FWHM for Lorentzian 1: {fwhm1}\")\n",
    "    print(f\"peak centre for lor1 is {mu1} Â± {gamma1}\")\n",
    "    print(f\"FWHM for Lorentzian 2: {fwhm2}\")\n",
    "    print(f\"peak centre for lor2 is {mu2} Â± {gamma2}\")\n",
    "\n",
    "fit_double_lorentzian(data, x, 'RT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not essential for calculating FWHM \n",
    "# # plots both parts of fit - the linear part and the isolated Gaussian\n",
    "# # this is to check it looks sensible\n",
    "\n",
    "# # loop through each dataset to plot the original data, combined fit, linear, and Gaussian parts\n",
    "# for i in range(y_values.shape[1]):\n",
    "#     y = y_values[:, i]\n",
    "    \n",
    "#     # retrieve parameters from the DataFrame\n",
    "#     m = params_df.loc[i, 'm']\n",
    "#     c = params_df.loc[i, 'c']\n",
    "#     A = params_df.loc[i, 'A']\n",
    "#     mu = params_df.loc[i, 'mu']\n",
    "#     sigma = params_df.loc[i, 'sigma']\n",
    "    \n",
    "#     # calculate indiviual components\n",
    "#     linear_component = m * x + c # linear\n",
    "#     gaussian_component = A * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) # Gaussian\n",
    "#     combined_fit = linear_component + gaussian_component  # linear + Gaussian\n",
    "\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "\n",
    "#     # plot 1: original data with combined fit\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.plot(x, y, 'b-', label=f'Original Data ({dataset_labels[i]} Â°C)')\n",
    "#     plt.plot(x, combined_fit, 'r--', label='Combined Fit (Linear + Gaussian)')\n",
    "#     plt.axvline(fit_range_min, color='k', linestyle='--', label='Fit range')\n",
    "#     plt.axvline(fit_range_max, color='k', linestyle='--')\n",
    "#     plt.title(f'{dataset_labels[i]} Â°C data')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # plot 2: linear component only\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(x, linear_component, 'g-', label='Linear Component (y = mx + c)')\n",
    "#     plt.legend()\n",
    "\n",
    "\n",
    "#     # plot 3: Gaussian component only\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(x, gaussian_component, 'm-', label=f'Gaussian Component for {dataset_labels[i]} Â°C sample')\n",
    "#     plt.legend()\n",
    "\n",
    "# #     # plot 4: Original data minus linear component (isolated Gaussian data)\n",
    "# #     plt.subplot(4, 1, 4)\n",
    "# #     plt.plot(x, y - linear_component, 'b-', label='Isolated Gaussian Data')\n",
    "# #     plt.plot(x, gaussian_component, 'r--', label='Fitted Gaussian')\n",
    "# #     plt.legend()\n",
    "\n",
    "#     plt.xlabel('x')\n",
    "#     plt.ylabel('Intensity')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbcd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_double_lorentzian_func(x, m, c, A1, mu1, gamma1, A2, mu2, gamma2):\n",
    "    linear_part = m * x + c\n",
    "    lorentzian1 = A1 * gamma1**2 / ((x - mu1)**2 + gamma1**2)\n",
    "    lorentzian2 = A2 * gamma2**2 / ((x - mu2)**2 + gamma2**2)\n",
    "    return linear_part + lorentzian1 + lorentzian2\n",
    "\n",
    "def fit_double_lorentzian(data, x, label):\n",
    "    # Ensure the label exists\n",
    "    if label not in params_df['Dataset'].values:\n",
    "        print(f\"Dataset label '{label}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Retrieve the y-values for the given label\n",
    "    label_index = params_df[params_df['Dataset'] == label].index[0]\n",
    "    y = y_values[:, label_index]\n",
    "\n",
    "    # Define fitting range\n",
    "    fit_mask = (x >= fit_range_min) & (x <= fit_range_max)\n",
    "    x_fit = x[fit_mask]\n",
    "    y_fit = y[fit_mask]\n",
    "\n",
    "    # Initial guesses for the parameters\n",
    "    initial_guess = [\n",
    "        1,                # slope (m) of the linear background\n",
    "        np.mean(y_fit),   # intercept (c) of the linear background\n",
    "        max(y_fit) / 2,   # amplitude of first Lorentzian (A1)\n",
    "        0.79,             # center of first Lorentzian (mu1)\n",
    "        0.07,             # width of first Lorentzian (gamma1)\n",
    "        max(y_fit) / 2,   # amplitude of second Lorentzian (A2)\n",
    "        0.87,             # center of second Lorentzian (mu2)\n",
    "        0.02              # width of second Lorentzian (gamma2)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Perform the curve fitting\n",
    "        params, covariance = curve_fit(\n",
    "            linear_double_lorentzian_func, \n",
    "            x_fit, \n",
    "            y_fit, \n",
    "            p0=initial_guess\n",
    "        )\n",
    "        m, c, A1, mu1, gamma1, A2, mu2, gamma2 = params\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x, y, 'b-', label=f'Original data ({label})Â°C')\n",
    "\n",
    "        combined_fit = linear_double_lorentzian_func(x, m, c, A1, mu1, gamma1, A2, mu2, gamma2)\n",
    "        plt.plot(x, combined_fit, 'r-', label='Double Lorentzian fit')\n",
    "\n",
    "        linear_part = m * x + c\n",
    "        plt.plot(x, linear_part, 'k--', label='Linear component')\n",
    "\n",
    "        lorentzian1 = A1 * gamma1**2 / ((x - mu1)**2 + gamma1**2)\n",
    "        lorentzian2 = A2 * gamma2**2 / ((x - mu2)**2 + gamma2**2)\n",
    "        plt.plot(x, lorentzian1 + linear_part, 'g--', label='Lorentzian 1')\n",
    "        plt.plot(x, lorentzian2 + linear_part, 'm--', label='Lorentzian 2')\n",
    "\n",
    "        plt.xlabel('q-values')\n",
    "        plt.ylabel('Intensity')\n",
    "        plt.title(f'Double Lorentzian Fit for {label}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate FWHMs and errors\n",
    "        fwhm1 = 2 * abs(gamma1)\n",
    "        fwhm2 = 2 * abs(gamma2)\n",
    "\n",
    "        if covariance is not None:\n",
    "            errors = np.sqrt(np.diag(covariance))  # Standard errors from covariance matrix\n",
    "            gamma1_error = errors[4]  # Error in gamma1\n",
    "            gamma2_error = errors[7]  # Error in gamma2\n",
    "            fwhm1_error = 2 * gamma1_error\n",
    "            fwhm2_error = 2 * gamma2_error\n",
    "\n",
    "            print(f\"FWHM for Lorentzian 1: {fwhm1} Â± {fwhm1_error}\")\n",
    "            print(f\"Peak center for Lorentzian 1: {mu1} Â± {errors[3]}\")\n",
    "            print(f\"FWHM for Lorentzian 2: {fwhm2} Â± {fwhm2_error}\")\n",
    "            print(f\"Peak center for Lorentzian 2: {mu2} Â± {errors[6]}\")\n",
    "        else:\n",
    "            print(f\"FWHM for Lorentzian 1: {fwhm1}\")\n",
    "            print(f\"Peak center for Lorentzian 1: {mu1}\")\n",
    "            print(f\"FWHM for Lorentzian 2: {fwhm2}\")\n",
    "            print(f\"Peak center for Lorentzian 2: {mu2}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Curve fitting failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_double_lorentzian(data, x, '140')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42969f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
